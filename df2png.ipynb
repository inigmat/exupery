{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtllgC5u0Ts13UuCp9nS/p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inigmat/exupery/blob/main/df2png.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing necessary packages for creating PNG files from tables. Initial run takes about 1 min\n",
        "!pip freeze | grep texlive || (apt-get update && apt-get install -y texlive texlive-latex-extra texlive-fonts-recommended dvipng)\n",
        "!pip freeze | grep imagemagick || apt-get install -y imagemagick\n",
        "!pip freeze | grep pdf2svg || apt-get install -y pdf2svg\n",
        "!pip freeze | grep cairosvg || pip install cairosvg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaDjZDu238ee",
        "outputId": "5de5a2e3-8828-48a4-95e2-fac34dc781c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Waiting for headers] [Con\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Fetched 336 kB in 2s (145 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "dvipng is already the newest version (1.15-1.1).\n",
            "texlive is already the newest version (2019.20200218-1).\n",
            "texlive-fonts-recommended is already the newest version (2019.20200218-1).\n",
            "texlive-latex-extra is already the newest version (2019.202000218-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "imagemagick is already the newest version (8:6.9.10.23+dfsg-2.1ubuntu11.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "pdf2svg is already the newest version (0.2.3-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n",
            "Requirement already satisfied: cairosvg in /usr/local/lib/python3.10/dist-packages (2.7.0)\n",
            "Requirement already satisfied: cairocffi in /usr/local/lib/python3.10/dist-packages (from cairosvg) (1.6.0)\n",
            "Requirement already satisfied: cssselect2 in /usr/local/lib/python3.10/dist-packages (from cairosvg) (0.7.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from cairosvg) (0.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from cairosvg) (8.4.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from cairosvg) (1.2.1)\n",
            "Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cairocffi->cairosvg) (1.15.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from cssselect2->cairosvg) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.1.0->cairocffi->cairosvg) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This code defines a function to convert a LaTeX table into a PNG image.\n",
        "\n",
        "Function:\n",
        "latex_table_to_png(obj, name)\n",
        "- Converts a LaTeX table code into a PNG image.\n",
        "- Parameters:\n",
        "    - obj: The LaTeX table code.\n",
        "    - name: The desired name for the output PNG file.\n",
        "- Steps:\n",
        "    1. Save the LaTeX code to a file named 'table.tex'.\n",
        "    2. Compile the LaTeX file into a DVI file using the 'latex' command.\n",
        "    3. Convert the DVI file to an SVG file using the 'dvisvgm' command.\n",
        "    4. Convert the SVG file to a PNG file using the 'cairosvg' library.\n",
        "    5. Download the PNG file using the 'files.download' function from Google Colab.\n",
        "\n",
        "Note:\n",
        "- The function assumes that the necessary packages and dependencies (such as 'latex', 'dvisvgm', and 'cairosvg') are installed and accessible in the environment.\n",
        "- If any errors occur during the execution, appropriate error messages will be displayed.\n",
        "'''\n",
        "\n",
        "from google.colab import files\n",
        "import subprocess\n",
        "import cairosvg\n",
        "\n",
        "\n",
        "def latex_table_to_png(obj, name):\n",
        "    # LaTeX table code\n",
        "    template = r'''\\documentclass[preview]{{standalone}}\n",
        "    \\usepackage{{booktabs}}\n",
        "    \\begin{{document}}\n",
        "    {}\n",
        "    \\end{{document}}\n",
        "    '''\n",
        "\n",
        "    # Save LaTeX code to a file\n",
        "    with open('table.tex', 'w') as f:\n",
        "        f.write(template.format(obj))\n",
        "\n",
        "    try:\n",
        "         # Compile LaTeX file to DVI file\n",
        "        subprocess.check_call(['latex', 'table.tex'])\n",
        "\n",
        "        # Convert DVI file to SVG file\n",
        "        subprocess.check_call(['dvisvgm', '--no-fonts', 'table.dvi', '-o', 'table.svg'])\n",
        "\n",
        "        # PNG file name\n",
        "        png_filename = f'{name}.png'\n",
        "\n",
        "        # Convert SVG file to PNG file\n",
        "        cairosvg.svg2png(url='table.svg', write_to=png_filename, scale=1.7)\n",
        "\n",
        "        # Download the file\n",
        "        files.download(png_filename)\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"Error executing command:\", e)\n",
        "\n",
        "    except IOError as e:\n",
        "        print(\"Error with file operations:\", e)\n"
      ],
      "metadata": {
        "id": "8oiTGxO39Ct5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "import pandas as pd\n",
        "\n",
        "CSV_URL = 'https://raw.githubusercontent.com/inigmat/exupery/main/files/bbs.csv'\n",
        "data = pd.read_csv(CSV_URL)\n",
        "bbs = data.drop(columns='index')\n",
        "bbs_latex = bbs.style.to_latex(hrules=True)\n",
        "latex_table_to_png(bbs_latex, 'bbs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "sR6NlzUN4aJa",
        "outputId": "ef9aae67-3bb1-4b53-ae38-153876d118a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_25032bbe-f730-48c7-9a86-b23909f8b00a\", \"bbs.png\", 78854)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Таблица результатов раскроя арматуры"
      ],
      "metadata": {
        "id": "ZrVVXeux6ICX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install binpacking\n",
        "\n",
        "# Check the csv data\n",
        "\n",
        "CSV_URL = 'https://raw.githubusercontent.com/inigmat/exupery/main/files/bbs.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FT8ra4OMnjl",
        "outputId": "1995bc1f-914b-4a8c-e6e8-f107d9ecfec0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting binpacking\n",
            "  Downloading binpacking-1.5.2.tar.gz (8.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from binpacking) (0.18.3)\n",
            "Building wheels for collected packages: binpacking\n",
            "  Building wheel for binpacking (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for binpacking: filename=binpacking-1.5.2-py3-none-any.whl size=10093 sha256=538a1fb595789f3cd6fb7d3789c956f792bf1a1342d678b512184f82c3cf1a6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/09/07/93d7c3a8acc3f39fc972dd12b8b8131fdd00f9e61ca09ed723\n",
            "Successfully built binpacking\n",
            "Installing collected packages: binpacking\n",
            "Successfully installed binpacking-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from binpacking import to_constant_volume\n",
        "\n",
        "# Constants\n",
        "BAR_LENGTH = 11700\n",
        "CSV_URL = CSV_URL\n",
        "\n",
        "\n",
        "def calculate_required_bars(bar_schedule: pd.DataFrame, bar_length: int) -> tuple:\n",
        "    \"\"\"\n",
        "    Calculates the cutting schemes based on input data (bar schedule)\n",
        "    containing the length and quantity of bars and the length of the bars in stock.\n",
        "    \"\"\"\n",
        "    items = []\n",
        "    # Extracting data from DataFrame\n",
        "    for length, quantity in zip(bar_schedule['Length'], bar_schedule['Qty']):\n",
        "        items.extend([length] * quantity)\n",
        "    # Calculating the cutting schemes using bin packing algorithm\n",
        "    cutting_scheme = to_constant_volume(items, bar_length)\n",
        "    return cutting_scheme\n",
        "\n",
        "\n",
        "def generate_cutting_table(cutting_data: dict) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a dataframe (cutting schedule) with quantity,\n",
        "    cuts, utilization, scrap, and diameter columns\n",
        "    based on the cutting data (cutting schemes).\n",
        "    \"\"\"\n",
        "    cutting_schedule = pd.DataFrame(columns=[\"Qty\", \"Cuts\", \"Utilization\", \"Scrap\", \"Dia\"])\n",
        "    # Processing cutting data for each diameter\n",
        "    for dia, cutting_schemes in cutting_data.items():\n",
        "        df_temp = pd.DataFrame(zip(cutting_schemes), columns=[\"Cuts\"])\n",
        "        # Calculate the quantity of each cutting scheme\n",
        "        df_temp[\"Qty\"] = df_temp[\"Cuts\"].apply(lambda x: f\"{cutting_schemes.count(x)}x\")\n",
        "        # Calculate the total length used by each cutting scheme\n",
        "        df_temp[\"Utilization\"] = df_temp[\"Cuts\"].apply(sum)\n",
        "        # Calculate the amount of scrap for each cutting scheme\n",
        "        df_temp[\"Scrap\"] = BAR_LENGTH - df_temp[\"Utilization\"]\n",
        "        # Add the diameter column\n",
        "        df_temp[\"Dia\"] = dia\n",
        "        # Change the type of values in the Cuts column to drop duplicates\n",
        "        df_temp[\"Cuts\"] = df_temp[\"Cuts\"].astype(str)\n",
        "        # Concatenate df_temp with cutting_scheme\n",
        "        cutting_schedule = pd.concat([cutting_schedule, df_temp], ignore_index=True)\n",
        "    # Drop duplicate rows\n",
        "    cutting_schedule = cutting_schedule.drop_duplicates()\n",
        "    # Reset the index\n",
        "    cutting_schedule = cutting_schedule.reset_index(drop=True)\n",
        "    return cutting_schedule\n",
        "\n",
        "\n",
        "def main() -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Executes the main workflow to calculate cutting schemes and generate a cutting schedule.\n",
        "    \"\"\"\n",
        "    # Read the data from CSV\n",
        "    data = pd.read_csv(CSV_URL)\n",
        "    cutting_data = {}\n",
        "    # Process data for each unique diameter\n",
        "    for dia in data['Dia'].unique():\n",
        "        data_dia = data[data['Dia'] == dia]\n",
        "        # Calculate the cutting schemes and store them in a dictionary\n",
        "        cutting_patterns = calculate_required_bars(data_dia, BAR_LENGTH)\n",
        "        cutting_data[dia] = cutting_patterns\n",
        "        # Print results\n",
        "        print(f'Required number of reinforcement bars with diameter {dia} mm: {len(cutting_patterns)} pcs.')\n",
        "        percent = ((data_dia['Qty'] * data_dia['Length']).sum()/(len(cutting_patterns) * BAR_LENGTH)) * 100\n",
        "        print(f'Total scrap: {round(100 - percent, 2)}%')\n",
        "    # Generate the cutting table\n",
        "    cutting_schedule = generate_cutting_table(cutting_data)\n",
        "    return cutting_schedule\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Execute the main function and store the resulting cutting table\n",
        "    cutting_schedule = main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwtwN2u0Mxkv",
        "outputId": "e0a8f728-6ef6-4e6b-9a3b-d190115c99ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required number of reinforcement bars with diameter 10 mm: 168 pcs.\n",
            "Total scrap: 2.32%\n",
            "Required number of reinforcement bars with diameter 12 mm: 138 pcs.\n",
            "Total scrap: 1.47%\n",
            "Required number of reinforcement bars with diameter 16 mm: 143 pcs.\n",
            "Total scrap: 3.76%\n",
            "Required number of reinforcement bars with diameter 20 mm: 759 pcs.\n",
            "Total scrap: 4.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cutting_schedule_L = cutting_schedule.style.to_latex(hrules=True)"
      ],
      "metadata": {
        "id": "JRQVpUD7M5c1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latex_table_to_png(cutting_schedule_L, 'cs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "O3i_saS-M_qD",
        "outputId": "8e7c43c2-92b4-47af-99a4-9d4bc80ef57b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ccd65d03-0a2f-4578-8cfb-cebcf0df9034\", \"cs.png\", 298772)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}